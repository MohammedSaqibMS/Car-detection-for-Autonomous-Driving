{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662178e4-c27c-490f-b3cd-b448c1f01b89",
   "metadata": {},
   "source": [
    "# Autonomous Driving - Car detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f824005-3e6a-4ee4-b933-2bce41063e72",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020fd79-ccb8-4a39-91c3-f744f4e8cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot as plt  # Import directly from matplotlib for consistency\n",
    "from PIL import Image\n",
    "\n",
    "# Custom utility functions\n",
    "from yolo_utils import (\n",
    "    read_classes, \n",
    "    read_anchors, \n",
    "    generate_colors, \n",
    "    preprocess_image, \n",
    "    draw_boxes, \n",
    "    scale_boxes\n",
    ")\n",
    "from yad2k.models.keras_yolo import (\n",
    "    yolo_head, \n",
    "    yolo_boxes_to_corners, \n",
    "    preprocess_true_boxes, \n",
    "    yolo_loss, \n",
    "    yolo_body\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6124c2-6119-4025-b299-b2b9bcd85311",
   "metadata": {},
   "source": [
    "## 1 - Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea1ebd-32b3-428a-a7dd-20df4733ba4e",
   "metadata": {},
   "source": [
    "## 2 - YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d6a75-fdaa-48a6-b2e8-e9bd8c549406",
   "metadata": {},
   "source": [
    "### 2.1 - More details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65617467-ce65-442c-82dd-cb93d89c4305",
   "metadata": {},
   "source": [
    "#### Inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a09cfd-310e-42d5-affc-61f83f95083f",
   "metadata": {},
   "source": [
    "#### Anchor Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20a67d-6f53-4600-bfe4-3a6eed993c05",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d05bb7-e1d8-446b-9754-f3191df1518e",
   "metadata": {},
   "source": [
    "#### class score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181ee95-d228-4899-81cf-840728f49e80",
   "metadata": {},
   "source": [
    "#### Visualizing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454894b9-9484-4789-a64c-4169ee2a7eff",
   "metadata": {},
   "source": [
    "#### Visualizing bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3e067-b8c5-4b9c-b922-722b7896707e",
   "metadata": {},
   "source": [
    "### 2.2 - Filtering with a threshold on a class scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684d33e-a99d-4517-afdf-ea5803d107e5",
   "metadata": {},
   "source": [
    "#### Implement `yolo_filter_boxes()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0d604-e492-42e6-9d62-446a9a4d4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modernized YOLO Filter Boxes Function\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Filters YOLO boxes by thresholding on object and class confidence.\n",
    "\n",
    "    Args:\n",
    "    box_confidence (tf.Tensor): Tensor of shape (19, 19, 5, 1) representing object confidence.\n",
    "    boxes (tf.Tensor): Tensor of shape (19, 19, 5, 4) containing box coordinates (b_x, b_y, b_h, b_w).\n",
    "    box_class_probs (tf.Tensor): Tensor of shape (19, 19, 5, 80) representing class probabilities.\n",
    "    threshold (float): Minimum confidence threshold for retaining boxes.\n",
    "\n",
    "    Returns:\n",
    "    tuple:\n",
    "        scores (tf.Tensor): Tensor of shape (None,) with class probability scores for selected boxes.\n",
    "        boxes (tf.Tensor): Tensor of shape (None, 4) containing coordinates of selected boxes.\n",
    "        classes (tf.Tensor): Tensor of shape (None,) containing class indices for selected boxes.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute box scores by multiplying object confidence with class probabilities\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "\n",
    "    # Step 2: Find the class with the highest score for each box and its corresponding score\n",
    "    box_classes = tf.argmax(box_scores, axis=-1)  # Index of the class with max score\n",
    "    box_class_scores = tf.reduce_max(box_scores, axis=-1)  # Maximum class score\n",
    "\n",
    "    # Step 3: Create a mask for boxes with scores above the threshold\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "\n",
    "    # Step 4: Apply the mask to filter scores, boxes, and classes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8c312-6abe-4d55-9eca-a145c67f7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests the yolo_filter_boxes function with random input data.\n",
    "# Generate random input tensors\n",
    "box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed=1)\n",
    "boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed=1)\n",
    "box_class_probs = tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed=1)\n",
    "\n",
    "# Call the yolo_filter_boxes function\n",
    "scores, filtered_boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=0.5)\n",
    "# Display results\n",
    "print(\"Example Scores:\", scores[:3].numpy())  # Convert tensors to NumPy for display\n",
    "print(\"Example Filtered Boxes:\", filtered_boxes[:3].numpy())\n",
    "print(\"Example Classes:\", classes[:3].numpy())\n",
    "print(\"Scores Shape:\", scores.shape)\n",
    "print(\"Boxes Shape:\", filtered_boxes.shape)\n",
    "print(\"Classes Shape:\", classes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a71d61-1a38-400f-90a9-b7e2bd6309ea",
   "metadata": {},
   "source": [
    "### 2.3 - Non max suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f431d87-0280-45dd-b85d-9c0c784b9af6",
   "metadata": {},
   "source": [
    "#### Implement IOU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f750334-cff8-4f03-9679-41b1c0933192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) between two bounding boxes.\n",
    "\n",
    "    Args:\n",
    "    box1 (list): First box with coordinates [x1, y1, x2, y2].\n",
    "    box2 (list): Second box with coordinates [x1, y1, x2, y2].\n",
    "\n",
    "    Returns:\n",
    "    float: IoU value between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assign variable names to coordinates for clarity\n",
    "    box1_x1, box1_y1, box1_x2, box1_y2 = box1\n",
    "    box2_x1, box2_y1, box2_x2, box2_y2 = box2\n",
    "\n",
    "    # Calculate intersection coordinates and dimensions\n",
    "    xi1 = np.maximum(box1_x1, box2_x1)\n",
    "    yi1 = np.maximum(box1_y1, box2_y1)\n",
    "    xi2 = np.minimum(box1_x2, box2_x2)\n",
    "    yi2 = np.minimum(box1_y2, box2_y2)\n",
    "\n",
    "    inter_width = max(xi2 - xi1, 0)  # Ensure non-negative width\n",
    "    inter_height = max(yi2 - yi1, 0)  # Ensure non-negative height\n",
    "    inter_area = inter_width * inter_height  # Intersection area\n",
    "\n",
    "    # Calculate areas of both boxes\n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
    "\n",
    "    # Calculate the union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb047db-754f-4f73-9b5e-bf925f5d1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 1: Boxes intersect\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4)\n",
    "print(f\"IoU for intersecting boxes: {iou(box1, box2):.2f}\")\n",
    "# Test case 2: Boxes do not intersect\n",
    "box1 = (1, 2, 3, 4)\n",
    "box2 = (5, 6, 7, 8)\n",
    "print(f\"IoU for non-intersecting boxes: {iou(box1, box2):.2f}\")\n",
    "# Test case 3: Boxes intersect at vertices only\n",
    "box1 = (1, 1, 2, 2)\n",
    "box2 = (2, 2, 3, 3)\n",
    "print(f\"IoU for boxes touching at vertices: {iou(box1, box2):.2f}\")\n",
    "# Test case 4: Boxes intersect at edge only\n",
    "box1 = (1, 1, 3, 3)\n",
    "box2 = (2, 3, 3, 4)\n",
    "print(f\"IoU for boxes touching at edges: {iou(box1, box2):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6484f-69e9-4a3d-a90c-11874b0f2a15",
   "metadata": {},
   "source": [
    "#### YOLO non-max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33401a95-7b52-4907-9ffe-ec847ae1d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply Non-Max Suppression (NMS) to filter overlapping bounding boxes.\n",
    "\n",
    "    Args:\n",
    "    scores (tf.Tensor): 1D tensor with shape (None,), confidence scores for each box.\n",
    "    boxes (tf.Tensor): 2D tensor with shape (None, 4), bounding box coordinates.\n",
    "    classes (tf.Tensor): 1D tensor with shape (None,), class predictions for each box.\n",
    "    max_boxes (int): Maximum number of boxes to keep after applying NMS.\n",
    "    iou_threshold (float): IOU threshold for deciding whether boxes overlap too much.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        scores: Filtered confidence scores.\n",
    "        boxes: Filtered bounding box coordinates.\n",
    "        classes: Filtered class predictions.\n",
    "    \"\"\"\n",
    "    # Ensure max_boxes is respected by creating a tensor\n",
    "    max_boxes_tensor = tf.constant(max_boxes, dtype=tf.int32, name=\"max_boxes\")\n",
    "\n",
    "    # Apply Non-Max Suppression to get indices of the boxes to keep\n",
    "    nms_indices = tf.image.non_max_suppression(\n",
    "        boxes=boxes,\n",
    "        scores=scores,\n",
    "        max_output_size=max_boxes,\n",
    "        iou_threshold=iou_threshold\n",
    "    )\n",
    "\n",
    "    # Gather the selected indices to filter scores, boxes, and classes\n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes, nms_indices)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a505ad-f0ee-42b5-a5d1-f0c3bae7d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the yolo_non_max_suppression function\n",
    "scores = tf.random.normal([54], mean=1, stddev=4, seed=1)\n",
    "boxes = tf.random.normal([54, 4], mean=1, stddev=4, seed=1)\n",
    "classes = tf.random.normal([54], mean=1, stddev=4, seed=1)\n",
    "\n",
    "# Apply the NMS function\n",
    "scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "\n",
    "# Display the results\n",
    "print(\"scores[2] =\", scores.numpy()[2])\n",
    "print(\"boxes[2] =\", boxes.numpy()[2])\n",
    "print(\"classes[2] =\", classes.numpy()[2])\n",
    "print(\"scores.shape =\", scores.numpy().shape)\n",
    "print(\"boxes.shape =\", boxes.numpy().shape)\n",
    "print(\"classes.shape =\", classes.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296b341-ea28-4b82-a3a2-b358686bba45",
   "metadata": {},
   "source": [
    "### 2.4 Wrapping up the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a952e-5b10-43d2-a3f0-96aaa9b976df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape=(720., 1280.), max_boxes=10, score_threshold=0.6, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Converts YOLO model outputs to filtered predictions (scores, boxes, and classes).\n",
    "\n",
    "    Args:\n",
    "    yolo_outputs (tuple): Contains 4 tensors from the YOLO model output:\n",
    "        - box_confidence: Tensor of shape (None, 19, 19, 5, 1)\n",
    "        - box_xy: Tensor of shape (None, 19, 19, 5, 2)\n",
    "        - box_wh: Tensor of shape (None, 19, 19, 5, 2)\n",
    "        - box_class_probs: Tensor of shape (None, 19, 19, 5, 80)\n",
    "    image_shape (tuple): Shape of the input image, e.g., (720., 1280.).\n",
    "    max_boxes (int): Maximum number of boxes to keep after filtering.\n",
    "    score_threshold (float): Minimum score to keep a box.\n",
    "    iou_threshold (float): IOU threshold for NMS filtering.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        scores: Filtered confidence scores.\n",
    "        boxes: Filtered bounding box coordinates.\n",
    "        classes: Filtered class predictions.\n",
    "    \"\"\"\n",
    "    # Unpack YOLO model outputs\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convert (box_xy, box_wh) to corner coordinates for compatibility\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Filter boxes based on confidence scores\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)\n",
    "\n",
    "    # Scale boxes to match the original image dimensions\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49224b37-fdcb-4908-920e-37f9d0213577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the yolo_filter_boxes function by providing random YOLO outputs and evaluating results\n",
    "# Generate random YOLO outputs for testing\n",
    "yolo_outputs = (\n",
    "    tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed=1),  # box_confidence\n",
    "    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed=1),  # box_xy\n",
    "    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed=1),  # box_wh\n",
    "    tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed=1)  # box_class_probs\n",
    ")\n",
    "# Define image shape and filtering parameters\n",
    "image_shape = (720., 1280.)  # Input image dimensions\n",
    "max_boxes = 10  # Maximum boxes after filtering\n",
    "score_threshold = 0.6  # Confidence score threshold\n",
    "iou_threshold = 0.5  # Non-max suppression IOU threshold\n",
    "# Call the yolo_eval function to process the outputs\n",
    "scores, boxes, classes = yolo_eval(\n",
    "    yolo_outputs, \n",
    "    image_shape=image_shape, \n",
    "    max_boxes=max_boxes, \n",
    "    score_threshold=score_threshold, \n",
    "    iou_threshold=iou_threshold\n",
    ")\n",
    "# Print results for debugging\n",
    "print(\"Scores[2]:\", scores.numpy()[2] if len(scores) > 2 else \"Not enough scores\")\n",
    "print(\"Boxes[2]:\", boxes.numpy()[2] if len(boxes) > 2 else \"Not enough boxes\")\n",
    "print(\"Classes[2]:\", classes.numpy()[2] if len(classes) > 2 else \"Not enough classes\")\n",
    "print(\"Scores shape:\", scores.shape)\n",
    "print(\"Boxes shape:\", boxes.shape)\n",
    "print(\"Classes shape:\", classes.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73418c5-a988-4fcf-9c81-3625fa4e2a65",
   "metadata": {},
   "source": [
    "## 3 - Test YOLO pretrained model on images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07db6f-4e98-4d6d-a2b0-96c205e3c703",
   "metadata": {},
   "source": [
    "### 3.1 - Defining classes, anchors, and image shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01feb5cb-5db9-432a-ae10-fa2b2d4dee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class names from the specified file.\n",
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "\n",
    "# Load anchor box dimensions from the specified file.\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "\n",
    "# Define the shape of the input image as height and width.\n",
    "image_shape = (720., 1280.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82294adc-e364-46b8-a9df-d34ecf1a9f1c",
   "metadata": {},
   "source": [
    "### 3.2 - Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f18db9-cf3e-41e7-9721-6d8a6c7e1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained YOLO model from the specified file.\n",
    "yolo_model = load_model(\"model_data/yolo.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c911f-2311-4311-83f0-81e2d13735bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary of the YOLO model architecture\n",
    "yolo_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2105e0-386a-4d10-84ef-e00d4136c101",
   "metadata": {},
   "source": [
    "### 3.3 - Convert output of the model to usable bounding box tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83129edf-a171-4a75-97a4-8e464565ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebf94b-0d42-4148-b38a-181f3068220f",
   "metadata": {},
   "source": [
    "### 3.4 - Filtering boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb15eed-4040-48ed-b88c-be7f1ce6fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the YOLO model's outputs to filter detections\n",
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19786a-33ba-4817-bd9a-5f96d2faaf74",
   "metadata": {},
   "source": [
    "### 3.5 - Run the graph on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88d638-e364-4b53-bff8-393d39c03a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file, yolo_model, class_names):\n",
    "    \"\"\"\n",
    "    Predicts bounding boxes for an image using a YOLO model.\n",
    "\n",
    "    Args:\n",
    "        image_file (str): Path to the input image file.\n",
    "        yolo_model (tf.keras.Model): The YOLO model used for prediction.\n",
    "        class_names (list): List of class names that YOLO can detect.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - out_scores (numpy.ndarray): Confidence scores for the predicted boxes.\n",
    "            - out_boxes (numpy.ndarray): Coordinates of the predicted bounding boxes.\n",
    "            - out_classes (numpy.ndarray): Class indices corresponding to the predicted boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image_path = os.path.join(\"images\", image_file)\n",
    "    image, image_data = preprocess_image(image_path, model_image_size=(608, 608))\n",
    "\n",
    "    # Run inference using the YOLO model (TensorFlow 2.x uses eager execution by default)\n",
    "    outputs = yolo_model(image_data, training=False)\n",
    "\n",
    "    # Extract predictions: scores, boxes, and classes\n",
    "    scores = outputs['scores']  # Replace with actual output key\n",
    "    boxes = outputs['boxes']    # Replace with actual output key\n",
    "    classes = outputs['classes']  # Replace with actual output key\n",
    "\n",
    "    # Rescale boxes to the original image size\n",
    "    image_width, image_height = image.size\n",
    "    boxes[:, [0, 2]] *= image_width\n",
    "    boxes[:, [1, 3]] *= image_height\n",
    "\n",
    "    # Filter and process outputs if needed (e.g., confidence threshold or NMS)\n",
    "    out_scores, out_boxes, out_classes = scores, boxes, classes\n",
    "\n",
    "    # Print number of boxes detected\n",
    "    print(f'Found {len(out_boxes)} boxes for {image_file}')\n",
    "\n",
    "    # Generate colors for bounding boxes\n",
    "    colors = generate_colors(class_names)\n",
    "\n",
    "    # Draw bounding boxes on the image and save the result\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    output_path = os.path.join(\"out\", image_file)\n",
    "    image.save(output_path, quality=90)\n",
    "\n",
    "    # Display the output image\n",
    "    output_image = ndimage.imread(output_path)\n",
    "    plt.imshow(output_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return out_scores, out_boxes, out_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36be5f2-47e7-4516-a89b-34fd45213fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted scores, boxes, and classes for the test image\n",
    "out_scores, out_boxes, out_classes = predict(\"test.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b440f3-fb97-432f-b615-09ca16ff2881",
   "metadata": {},
   "source": [
    "**References**: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's GitHub repository. The pre-trained weights used in this exercise came from the official YOLO website. \n",
    "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) (2015)\n",
    "- Joseph Redmon, Ali Farhadi - [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (2016)\n",
    "- Allan Zelener - [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)\n",
    "- The official YOLO website (https://pjreddie.com/darknet/yolo/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b97cc8-6caa-4db3-8f7d-fee3a8ac6937",
   "metadata": {},
   "source": [
    "**Car detection dataset**:\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">The Drive.ai Sample Dataset</span> (provided by drive.ai) is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>. We are grateful to Brody Huval, Chih Hu and Rahul Patel for  providing this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7c945-a4e3-4db9-bf5d-ede757fa7e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
